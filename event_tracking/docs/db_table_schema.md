## ğŸ§± PostgreSQL Schema è¨­è¨ˆ

1. `tenants`ï¼šç§Ÿæˆ¶å®šç¾© (å¦‚ ä¼æ¥­ã€å“ç‰Œã€å€‹äºº)
2. `applications`ï¼šè¨»å†Šçš„æ‡‰ç”¨ç¨‹å¼ï¼ˆä¾‹å¦‚ Web Appã€Mobile Appï¼‰
3. `platforms`ï¼šå¹³å°å®šç¾©ï¼ˆå¦‚ Webã€iOSã€Androidï¼‰
4. `events`ï¼šå®šç¾©å“ªäº›äº‹ä»¶è¦è¢«è¿½è¹¤
5. `event_fields`ï¼šå®šç¾©äº‹ä»¶æ‰€éœ€æ¬„ä½ï¼ˆæ¬„ä½åç¨± + è³‡æ–™å‹æ…‹ï¼‰
6. `sessions`ï¼šä½¿ç”¨è€… Sessionï¼ˆåŒ¿åæˆ–å…·åï¼‰
7. `event_logs`ï¼šäº‹ä»¶å¯¦éš›ç´€éŒ„ï¼ˆä¸å«æ¬„ä½å€¼ï¼Œå¯«å…¥ Kafka å¾Œé€è‡³ OLAP å„²å­˜ï¼‰

---

```sql
-- ç§Ÿæˆ¶è³‡è¨Š
CREATE TABLE tenants (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name TEXT NOT NULL UNIQUE, -- ç§Ÿæˆ¶åç¨±ï¼ˆå¦‚å…¬å¸åç¨±ï¼‰
    description TEXT, -- ç§Ÿæˆ¶æè¿°
    created_at TIMESTAMP NOT NULL DEFAULT now(), -- å»ºç«‹æ™‚é–“
    updated_at TIMESTAMP NOT NULL DEFAULT now(), -- æ›´æ–°æ™‚é–“
    CONSTRAINT tenant_name_unique UNIQUE (name) -- ç¢ºä¿æ¯å€‹ç§Ÿæˆ¶çš„åç¨±å”¯ä¸€
);

COMMENT ON COLUMN tenants.name IS 'ç§Ÿæˆ¶åç¨±ï¼ˆå¦‚å…¬å¸åç¨±ï¼‰';
COMMENT ON COLUMN tenants.description IS 'ç§Ÿæˆ¶æè¿°';
COMMENT ON COLUMN tenants.created_at IS 'ç§Ÿæˆ¶å‰µå»ºçš„æ™‚é–“æˆ³';
COMMENT ON COLUMN tenants.updated_at IS 'ç§Ÿæˆ¶æœ€å¾Œä¸€æ¬¡æ›´æ–°çš„æ™‚é–“æˆ³';

CREATE UNIQUE INDEX idx_tenants_name ON tenants (name);


-- æ‡‰ç”¨ç¨‹å¼è¨»å†Šè³‡è¨Š
CREATE TABLE applications (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    tenant_id UUID NOT NULL REFERENCES tenants(id) ON DELETE CASCADE, -- ç§Ÿæˆ¶ ID
    name TEXT NOT NULL, -- æ‡‰ç”¨ç¨‹å¼åç¨±
    api_key TEXT UNIQUE NOT NULL, -- æ‡‰ç”¨ç¨‹å¼çš„ API å¯†é‘°
    description TEXT, -- æ‡‰ç”¨ç¨‹å¼æè¿°
    created_at TIMESTAMP NOT NULL DEFAULT now(), -- æ‡‰ç”¨ç¨‹å¼å‰µå»ºæ™‚é–“
    updated_at TIMESTAMP NOT NULL DEFAULT now(), -- æ‡‰ç”¨ç¨‹å¼æ›´æ–°æ™‚é–“
    CONSTRAINT tenant_app_name_unique UNIQUE (tenant_id, name) -- ç¢ºä¿æ¯å€‹ç§Ÿæˆ¶ä¸­çš„æ‡‰ç”¨ç¨‹å¼åç¨±å”¯ä¸€
);

COMMENT ON COLUMN applications.tenant_id IS 'é—œè¯çš„ç§Ÿæˆ¶ ID';
COMMENT ON COLUMN applications.name IS 'æ‡‰ç”¨ç¨‹å¼åç¨±';
COMMENT ON COLUMN applications.api_key IS 'æ‡‰ç”¨ç¨‹å¼çš„ API å¯†é‘°';
COMMENT ON COLUMN applications.description IS 'æ‡‰ç”¨ç¨‹å¼æè¿°';
COMMENT ON COLUMN applications.created_at IS 'æ‡‰ç”¨ç¨‹å¼å‰µå»ºæ™‚é–“';
COMMENT ON COLUMN applications.updated_at IS 'æ‡‰ç”¨ç¨‹å¼æ›´æ–°æ™‚é–“';

CREATE UNIQUE INDEX idx_applications_tenant_id_name ON applications (tenant_id, name);
CREATE UNIQUE INDEX idx_applications_api_key ON applications (api_key);

-- æ”¯æ´çš„å¹³å°ç¨®é¡
CREATE TABLE platforms (
    id SERIAL PRIMARY KEY, -- å¹³å° ID
    name TEXT NOT NULL UNIQUE, -- å¹³å°åç¨±
    created_at TIMESTAMP NOT NULL DEFAULT now() -- å‰µå»ºæ™‚é–“
);

COMMENT ON COLUMN platforms.name IS 'å¹³å°åç¨±ï¼ˆå¦‚ Web, iOS, Androidï¼‰';
COMMENT ON COLUMN platforms.created_at IS 'å¹³å°å‰µå»ºæ™‚é–“';

CREATE UNIQUE INDEX idx_platforms_name ON platforms (name);


-- å®šç¾©äº‹ä»¶é¡å‹
CREATE TABLE events (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    application_id UUID NOT NULL REFERENCES applications(id) ON DELETE CASCADE, -- é—œè¯çš„æ‡‰ç”¨ç¨‹å¼ ID
    platform_id INTEGER REFERENCES platforms(id), -- é—œè¯çš„å¹³å° ID
    name TEXT NOT NULL, -- äº‹ä»¶åç¨±
    description TEXT, -- äº‹ä»¶æè¿°
    is_active BOOLEAN DEFAULT TRUE, -- äº‹ä»¶æ˜¯å¦å•Ÿç”¨
    created_at TIMESTAMP NOT NULL DEFAULT now(), -- äº‹ä»¶å‰µå»ºæ™‚é–“
    updated_at TIMESTAMP NOT NULL DEFAULT now(), -- äº‹ä»¶æ›´æ–°æ™‚é–“
    CONSTRAINT app_event_name_unique UNIQUE (application_id, name) -- ç¢ºä¿æ¯å€‹æ‡‰ç”¨ç¨‹å¼å…§çš„äº‹ä»¶åç¨±å”¯ä¸€
);

COMMENT ON COLUMN events.application_id IS 'é—œè¯çš„æ‡‰ç”¨ç¨‹å¼ ID';
COMMENT ON COLUMN events.platform_id IS 'é—œè¯çš„å¹³å° ID';
COMMENT ON COLUMN events.name IS 'äº‹ä»¶åç¨±';
COMMENT ON COLUMN events.description IS 'äº‹ä»¶æè¿°';
COMMENT ON COLUMN events.is_active IS 'äº‹ä»¶æ˜¯å¦å•Ÿç”¨';
COMMENT ON COLUMN events.created_at IS 'äº‹ä»¶å‰µå»ºæ™‚é–“';
COMMENT ON COLUMN events.updated_at IS 'äº‹ä»¶æ›´æ–°æ™‚é–“';

CREATE UNIQUE INDEX idx_events_application_id_name ON events (application_id, name);
CREATE INDEX idx_events_platform_id ON events (platform_id);

-- æ¯å€‹äº‹ä»¶å®šç¾©å…¶æ¬„ä½èˆ‡è³‡æ–™å‹åˆ¥ï¼ˆåƒ… schema å®šç¾©ï¼‰
CREATE TABLE event_fields (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE, -- é—œè¯çš„äº‹ä»¶ ID
    name TEXT NOT NULL, -- æ¬„ä½åç¨±
    data_type TEXT NOT NULL CHECK (data_type IN ('string', 'int', 'float', 'boolean', 'datetime', 'json')), -- è³‡æ–™å‹åˆ¥
    is_required BOOLEAN DEFAULT FALSE, -- æ¬„ä½æ˜¯å¦ç‚ºå¿…å¡«
    description TEXT, -- æ¬„ä½æè¿°
    created_at TIMESTAMP NOT NULL DEFAULT now(), -- æ¬„ä½å‰µå»ºæ™‚é–“
    CONSTRAINT event_field_unique UNIQUE (event_id, name) -- ç¢ºä¿æ¯å€‹äº‹ä»¶ä¸­çš„æ¬„ä½åç¨±å”¯ä¸€
);

COMMENT ON COLUMN event_fields.event_id IS 'é—œè¯çš„äº‹ä»¶ ID';
COMMENT ON COLUMN event_fields.name IS 'æ¬„ä½åç¨±';
COMMENT ON COLUMN event_fields.data_type IS 'è³‡æ–™å‹åˆ¥';
COMMENT ON COLUMN event_fields.is_required IS 'æ˜¯å¦ç‚ºå¿…å¡«æ¬„ä½';
COMMENT ON COLUMN event_fields.description IS 'æ¬„ä½æè¿°';
COMMENT ON COLUMN event_fields.created_at IS 'æ¬„ä½å‰µå»ºæ™‚é–“';

CREATE UNIQUE INDEX idx_event_fields_event_id_name ON event_fields (event_id, name);

-- Sessionï¼Œå¯ç”± SDK åˆå§‹åŒ–æ™‚å»ºç«‹ï¼Œèˆ‡åŒ¿åè¨ªå®¢æˆ– user_id ç¶å®š
CREATE TABLE sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    application_id UUID NOT NULL REFERENCES applications(id) ON DELETE CASCADE, -- é—œè¯çš„æ‡‰ç”¨ç¨‹å¼ ID
    platform_id INTEGER NOT NULL REFERENCES platforms(id), -- é—œè¯çš„å¹³å° ID
    session_key TEXT NOT NULL UNIQUE, -- Session å”¯ä¸€éµ
    user_id TEXT, -- ä½¿ç”¨è€… IDï¼ˆå¯é¸ï¼‰
    user_agent TEXT, -- ä½¿ç”¨è€…ä»£ç†ï¼ˆç€è¦½å™¨ / è¨­å‚™å‹è™Ÿï¼‰
    ip_address TEXT, -- ä½¿ç”¨è€… IP åœ°å€
    started_at TIMESTAMP NOT NULL DEFAULT now(), -- Session é–‹å§‹æ™‚é–“
    ended_at TIMESTAMP, -- Session çµæŸæ™‚é–“
    created_at TIMESTAMP NOT NULL DEFAULT now() -- Session å‰µå»ºæ™‚é–“
);

COMMENT ON COLUMN sessions.application_id IS 'é—œè¯çš„æ‡‰ç”¨ç¨‹å¼ ID';
COMMENT ON COLUMN sessions.platform_id IS 'é—œè¯çš„å¹³å° ID';
COMMENT ON COLUMN sessions.session_key IS 'Session å”¯ä¸€éµ';
COMMENT ON COLUMN sessions.user_id IS 'ä½¿ç”¨è€… IDï¼ˆåŒ¿åæˆ–ç™»å…¥å¸³è™Ÿ IDï¼‰';
COMMENT ON COLUMN sessions.user_agent IS 'ä½¿ç”¨è€…ä»£ç†';
COMMENT ON COLUMN sessions.ip_address IS 'ä½¿ç”¨è€… IP åœ°å€';
COMMENT ON COLUMN sessions.started_at IS 'Session é–‹å§‹æ™‚é–“';
COMMENT ON COLUMN sessions.ended_at IS 'Session çµæŸæ™‚é–“';
COMMENT ON COLUMN sessions.created_at IS 'Session å‰µå»ºæ™‚é–“';

CREATE UNIQUE INDEX idx_sessions_session_key ON sessions (session_key);
CREATE INDEX idx_sessions_application_id_user_id ON sessions (application_id, user_id);

-- å¯¦éš›äº‹ä»¶è¨˜éŒ„ï¼ˆåƒ…ç´€éŒ„ä¸»å¹¹ï¼Œæ¬„ä½è³‡æ–™å¯«å…¥ Kafka â†’ ClickHouseï¼‰
CREATE TABLE event_logs (
    id UUID, -- è¨˜éŒ„å”¯ä¸€ID
    application_id UUID NOT NULL REFERENCES applications(id) ON DELETE CASCADE, -- é—œè¯çš„æ‡‰ç”¨ç¨‹å¼ ID
    session_id UUID REFERENCES sessions(id) ON DELETE SET NULL, -- é—œè¯çš„ Session ID
    event_id UUID NOT NULL REFERENCES events(id) ON DELETE CASCADE, -- é—œè¯çš„äº‹ä»¶ ID
    platform_id INTEGER NOT NULL REFERENCES platforms(id), -- é—œè¯çš„å¹³å° ID
    created_at TIMESTAMP NOT NULL DEFAULT now(), -- è¨˜éŒ„å‰µå»ºæ™‚é–“
    properties JSONB, -- å‚™æ´è¨˜éŒ„ï¼ˆè£œå……æ¬„ä½è³‡æ–™ï¼‰
    indexed BOOLEAN DEFAULT FALSE, -- æ˜¯å¦å·²ç¶“å»ºç«‹ç´¢å¼•

    CONSTRAINT event_logs_pk PRIMARY KEY (id, created_at), -- ä¸»éµéœ€è¦åŒ…å«åˆ†å€éµ
    CONSTRAINT event_logs_created_at CHECK (created_at <= now()) -- é˜²æ­¢æœªä¾†æ—¥æœŸæ’å…¥
)
PARTITION BY RANGE (created_at); -- æŒ‰ç…§ created_at æ¬„ä½çš„ç¯„åœé€²è¡Œåˆ†å€

COMMENT ON COLUMN event_logs.application_id IS 'é—œè¯çš„æ‡‰ç”¨ç¨‹å¼ ID';
COMMENT ON COLUMN event_logs.session_id IS 'é—œè¯çš„ Session ID';
COMMENT ON COLUMN event_logs.event_id IS 'é—œè¯çš„äº‹ä»¶ ID';
COMMENT ON COLUMN event_logs.platform_id IS 'é—œè¯çš„å¹³å° ID';
COMMENT ON COLUMN event_logs.created_at IS 'è¨˜éŒ„å‰µå»ºæ™‚é–“';
COMMENT ON COLUMN event_logs.properties IS 'äº‹ä»¶çš„å‚™æ´è¨˜éŒ„';
COMMENT ON COLUMN event_logs.indexed IS 'æ˜¯å¦å·²ç¶“å»ºç«‹ç´¢å¼•';

CREATE INDEX idx_event_logs_application_id_created_at ON event_logs (application_id, created_at);
CREATE INDEX idx_event_logs_session_id ON event_logs (session_id);
CREATE INDEX idx_event_logs_event_id ON event_logs (event_id);
CREATE INDEX idx_event_logs_platform_id ON event_logs (platform_id);

```

---

### ğŸ”– è£œå……èªªæ˜

- `event_logs.properties` æ˜¯å‚™æ´è¨˜éŒ„ï¼Œä¸»ç³»çµ±æœƒå°‡äº‹ä»¶ JSON é€å¾€ Kafka â†’ ClickHouseã€‚
- å¯è€ƒæ…®å»ºç«‹éƒ¨åˆ†ç´¢å¼•æ¬„ä½æ–¼ PostgreSQLï¼Œä¾›ç°¡å–®æŸ¥è©¢æˆ– Debug ä½¿ç”¨ã€‚
- ClickHouse å°‡ä½œç‚ºä¸»è¦å„²å­˜èˆ‡åˆ†æçš„è³‡æ–™å€‰åº«ã€‚

---

## ğŸ§± ClickHouse Schema è¨­è¨ˆ

### è¨­è¨ˆç›®æ¨™

- å„²å­˜å¤§é‡è¿½è¹¤äº‹ä»¶è³‡æ–™
- æ”¯æ´è‡ªå®šç¾©æ¬„ä½ï¼ˆFlexible Schemaï¼‰
- å¯ä¾æ™‚é–“ã€å¹³å°ã€äº‹ä»¶é¡å‹å¿«é€ŸæŸ¥è©¢
- ä¾› OLAP å·¥å…·ï¼ˆå¦‚ Grafanaã€Metabaseï¼‰æ•´åˆ

---

#### 1. **`tenants`**ï¼šç§Ÿæˆ¶ä¸»è¡¨

```sql
CREATE TABLE tenants (
    id UUID DEFAULT generateUUIDv4(),
    name String,
    description String,
    created_at DateTime DEFAULT now(),
    updated_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(created_at)
ORDER BY (id)
SETTINGS index_granularity = 8192;

-- Index å»ºè­°
CREATE INDEX idx_tenants_name ON tenants (name) TYPE minmax GRANULARITY 4;
```

#### 2. **`applications`**ï¼šæ¯å€‹ç§Ÿæˆ¶çš„æ‡‰ç”¨ç¨‹å¼

```sql
CREATE TABLE applications (
    id UUID DEFAULT generateUUIDv4(),
    tenant_id UUID,
    name String,
    api_key String,
    description String,
    created_at DateTime DEFAULT now(),
    updated_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(created_at)  -- ä¾ç…§å‰µå»ºæ™‚é–“åˆ†å€
ORDER BY (tenant_id, id)           -- ä¾ç§Ÿæˆ¶IDæ’åºï¼Œä¿è­‰æ¯å€‹ç§Ÿæˆ¶çš„æ‡‰ç”¨ç¨‹å¼èƒ½å¤ ç¨ç«‹æŸ¥è©¢
SETTINGS index_granularity = 8192;

-- Index å»ºè­°
CREATE INDEX idx_applications_tenant_id_name ON applications (tenant_id, name) TYPE minmax GRANULARITY 4;
CREATE INDEX idx_applications_api_key ON applications (api_key) TYPE minmax GRANULARITY 4;
```

#### 3. **`platforms`**ï¼šå¹³å°é¡å‹ï¼ˆWeb, iOS, Android ç­‰ï¼‰

```sql
CREATE TABLE platforms (
    id UInt32,
    tenant_id UUID,  -- ä½¿å¹³å°èˆ‡ç§Ÿæˆ¶ç›¸é—œè¯
    name String,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(created_at)
ORDER BY (tenant_id, id)           -- ä¾ç§Ÿæˆ¶IDæ’åº
SETTINGS index_granularity = 8192;

-- Index å»ºè­°
CREATE INDEX idx_platforms_tenant_id_name ON platforms (tenant_id, name) TYPE minmax GRANULARITY 4;
```

#### 4. **`events`**ï¼šäº‹ä»¶å®šç¾©

```sql
CREATE TABLE events (
    id UUID DEFAULT generateUUIDv4(),
    tenant_id UUID,
    application_id UUID,
    platform_id UInt32,
    name String,
    description String,
    is_active UInt8 DEFAULT 1,
    created_at DateTime DEFAULT now(),
    updated_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(created_at)
ORDER BY (tenant_id, application_id, id)  -- ç¢ºä¿æ¯å€‹ç§Ÿæˆ¶çš„äº‹ä»¶è³‡æ–™èƒ½å¤ é«˜æ•ˆæŸ¥è©¢
SETTINGS index_granularity = 8192;

-- Index å»ºè­°
CREATE INDEX idx_events_tenant_id_application_id_name ON events (tenant_id, application_id, name) TYPE minmax GRANULARITY 4;
CREATE INDEX idx_events_platform_id ON events (platform_id) TYPE minmax GRANULARITY 4;
```

#### 5. **`event_fields`**ï¼šäº‹ä»¶æ¬„ä½å®šç¾©

```sql
CREATE TABLE event_fields (
    id UUID DEFAULT generateUUIDv4(),
    tenant_id UUID,
    event_id UUID,
    name String,
    data_type String,
    is_required UInt8 DEFAULT 0,
    description String,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(created_at)
ORDER BY (tenant_id, event_id, id)  -- ç¢ºä¿æ¯å€‹ç§Ÿæˆ¶çš„æ¬„ä½è³‡æ–™èƒ½å¤ é«˜æ•ˆæŸ¥è©¢
SETTINGS index_granularity = 8192;

-- Index å»ºè­°
CREATE INDEX idx_event_fields_tenant_id_event_id_name ON event_fields (tenant_id, event_id, name) TYPE minmax GRANULARITY 4;
```

#### 6. **`sessions`**ï¼šSession å®šç¾©

```sql
CREATE TABLE sessions (
    id UUID DEFAULT generateUUIDv4(),
    tenant_id UUID,
    application_id UUID,
    platform_id UInt32,
    session_key String,
    user_id String,
    user_agent String,
    ip_address String,
    started_at DateTime DEFAULT now(),
    ended_at DateTime,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(created_at)
ORDER BY (tenant_id, application_id, id)  -- ç¢ºä¿æ¯å€‹ç§Ÿæˆ¶çš„æœƒè©±è³‡æ–™èƒ½å¤ é«˜æ•ˆæŸ¥è©¢
SETTINGS index_granularity = 8192;

-- Index å»ºè­°
CREATE INDEX idx_sessions_tenant_id_user_id ON sessions (tenant_id, user_id) TYPE minmax GRANULARITY 4;
CREATE INDEX idx_sessions_session_key ON sessions (session_key) TYPE minmax GRANULARITY 4;
```

#### 7. **`event_logs`**ï¼šäº‹ä»¶æ—¥èªŒ

```sql
CREATE TABLE event_logs (
    id UUID DEFAULT generateUUIDv4(),
    tenant_id UUID,
    application_id UUID,
    session_id UUID,
    event_id UUID,
    platform_id UInt32,
    created_at DateTime DEFAULT now(),
    properties JSONB,
    indexed UInt8 DEFAULT 0
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(created_at)
ORDER BY (tenant_id, application_id, event_id, created_at)  -- ç¢ºä¿æ¯å€‹ç§Ÿæˆ¶çš„äº‹ä»¶æ—¥èªŒèƒ½å¤ é«˜æ•ˆæŸ¥è©¢
SETTINGS index_granularity = 8192;

-- Index å»ºè­°
CREATE INDEX idx_event_logs_tenant_id_application_id_created_at ON event_logs (tenant_id, application_id, created_at) TYPE minmax GRANULARITY 4;
CREATE INDEX idx_event_logs_session_id ON event_logs (session_id) TYPE minmax GRANULARITY 4;
CREATE INDEX idx_event_logs_event_id ON event_logs (event_id) TYPE minmax GRANULARITY 4;
CREATE INDEX idx_event_logs_platform_id ON event_logs (platform_id) TYPE minmax GRANULARITY 4;
```

---

### **è¨­è¨ˆèªªæ˜èˆ‡å»ºè­°**

1. **Partitioning**:

   - æ‰€æœ‰è¡¨æ ¼éƒ½ä½¿ç”¨ `toYYYYMM(created_at)` ä¾†é€²è¡Œ Partitionï¼Œä½¿å¾—æ¯å€‹æœˆçš„è³‡æ–™åˆ†ç‚ºä¸€å€‹ Partitionã€‚é€™æ¨£å¯ä»¥æœ‰æ•ˆåœ°å°‡è³‡æ–™åˆ†å€ï¼Œä¾¿æ–¼é«˜æ•ˆæŸ¥è©¢å’Œæ•¸æ“šç®¡ç†ã€‚
   - å¯ä»¥æ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´ Partition ç­–ç•¥ï¼Œä¾‹å¦‚å¯ä»¥æ ¹æ“š `tenant_id` ä¾†åˆ†å€ï¼ˆå°¤å…¶ç•¶æœ‰å¤šç§Ÿæˆ¶ä¸”æŸ¥è©¢æœƒé›†ä¸­æ–¼æŸäº›ç§Ÿæˆ¶æ™‚ï¼‰ã€‚

2. **Indexing**:

   - **Minmax ç´¢å¼•**ï¼šä½¿ç”¨ `minmax` é¡å‹çš„ç´¢å¼•ä¾†åŠ é€ŸæŸ¥è©¢ç¯„åœæ¢ä»¶ï¼ˆå¦‚æ™‚é–“ç¯„åœã€ID ç¯„åœç­‰ï¼‰çš„æŸ¥è©¢ã€‚
   - æ¯å€‹è¡¨çš„ä¸»è¦æŸ¥è©¢æ¢ä»¶ï¼ˆå¦‚ç§Ÿæˆ¶ã€æ‡‰ç”¨ç¨‹å¼åç¨±ã€äº‹ä»¶åç¨±ã€Session ID ç­‰ï¼‰éƒ½æ‡‰è©²æœ‰ç´¢å¼•ä»¥åŠ é€ŸæŸ¥è©¢ã€‚
   - ä½¿ç”¨ `index_granularity` è¨­å®šä¾†å„ªåŒ–æŸ¥è©¢æ€§èƒ½ï¼Œé»˜èªå€¼ç‚º 8192ï¼Œé€™æ˜¯è¼ƒç‚ºé€šç”¨çš„é…ç½®ã€‚

3. **JSONB**ï¼š

   - `event_logs` è¡¨ä¸­çš„ `properties` æ¬„ä½è¨­ç‚º `JSONB` é¡å‹ï¼Œå…è¨±éˆæ´»å„²å­˜äº‹ä»¶å±¬æ€§æ•¸æ“šï¼Œä¸¦ä¸”ä¾¿æ–¼è™•ç†ä¸åŒäº‹ä»¶çš„å¤šè®Šçµæ§‹ã€‚

---

## ğŸ“¦ ğŸ“¡ Kafka Topic çµæ§‹è¨­è¨ˆ

é€é Apache NiFi Kafka â†’ ClickHouse

### 1. Topic å‘½åè¦å‰‡

```
event_logs.{env}.{platform}
```

- `env`: prod, staging, dev
- `platform`: web, ios, android

ä¾‹å¦‚ï¼š

- `event_logs.prod.web`
- `event_logs.dev.ios`

### 2. Kafka Message Formatï¼ˆJSONï¼‰

```json
{
  "tenant_id": "tenant_123", // æ–°å¢ç§Ÿæˆ¶ID
  "event_id": "uuid", // äº‹ä»¶ID
  "event_name": "product_click", // äº‹ä»¶åç¨±
  "application_id": "uuid", // æ‡‰ç”¨ID
  "platform": "web", // å¹³å°é¡å‹
  "session_id": "uuid", // æœƒè©±ID
  "user_id": "anonymous", // ç”¨æˆ¶ID
  "created_at": "2025-05-03T12:00:00Z", // äº‹ä»¶ç™¼ç”Ÿæ™‚é–“
  "ip_address": "192.168.1.1", // ç”¨æˆ¶IP
  "user_agent": "Mozilla/5.0", // ç”¨æˆ¶ä»£ç†
  "properties": {
    "product_id": "P123", // ç”¢å“ID
    "category": "books", // ç”¢å“åˆ†é¡
    "price": 299 // ç”¢å“åƒ¹æ ¼
  }
}
```

3. NiFi å¯é€é `ReplaceText` â†’ `ConvertRecord` â†’ `PutClickHouseRecord` å¯«å…¥æ­¤è³‡æ–™è¡¨ã€‚

---

## ğŸ” OLAP åˆ†æå»ºè­°æŸ¥è©¢ï¼ˆç¯„ä¾‹ï¼‰

åœ¨ä½¿ç”¨ ClickHouse é€²è¡Œ OLAP (è¯æ©Ÿåˆ†æè™•ç†) åˆ†ææ™‚ï¼Œå»ºè­°è¨­è¨ˆæŸ¥è©¢ä»¥æ”¯æ´é«˜æ•ˆçš„å¤šç¶­åˆ†æã€‚ä»¥ä¸‹æ˜¯é‡å°æ‚¨çš„ schema è¨­è¨ˆçš„å¸¸è¦‹ OLAP æŸ¥è©¢å»ºè­°ï¼š

### 1. **æŒ‰å¹³å°å’Œäº‹ä»¶é¡å‹çµ±è¨ˆäº‹ä»¶æ¬¡æ•¸**

æ­¤æŸ¥è©¢å¯ä»¥å¹«åŠ©æ‚¨çµ±è¨ˆä¸åŒå¹³å°ä¸Šçš„äº‹ä»¶é¡å‹æ•¸é‡ï¼Œä¸¦æä¾›åŸºæ–¼å¹³å°çš„äº‹ä»¶åˆ†æã€‚

```sql
SELECT
    p.name AS platform_name,
    e.name AS event_name,
    COUNT(el.id) AS event_count
FROM event_logs el
JOIN platforms p ON el.platform_id = p.id
JOIN events e ON el.event_id = e.id
WHERE el.created_at >= '2025-01-01' AND el.created_at < '2025-02-01'
GROUP BY platform_name, event_name
ORDER BY event_count DESC
LIMIT 10;
```

### 2. **æŒ‰ç§Ÿæˆ¶çµ±è¨ˆå„å¹³å°äº‹ä»¶æ¬¡æ•¸**

æ­¤æŸ¥è©¢æœ‰åŠ©æ–¼åˆ†æå„ç§Ÿæˆ¶åœ¨ä¸åŒå¹³å°ä¸Šè§¸ç™¼çš„äº‹ä»¶æ•¸é‡ï¼Œé©ç”¨æ–¼å¤šç§Ÿæˆ¶ç³»çµ±ã€‚

```sql
SELECT
    t.name AS tenant_name,
    p.name AS platform_name,
    COUNT(el.id) AS event_count
FROM event_logs el
JOIN applications a ON el.application_id = a.id
JOIN tenants t ON a.tenant_id = t.id
JOIN platforms p ON el.platform_id = p.id
WHERE el.created_at >= '2025-01-01' AND el.created_at < '2025-02-01'
GROUP BY tenant_name, platform_name
ORDER BY event_count DESC
LIMIT 10;
```

### 3. **æŒ‰æ—¥æœŸç¯„åœåˆ†æäº‹ä»¶ç™¼ç”Ÿé »ç‡**

æ­¤æŸ¥è©¢å¯ä»¥å¹«åŠ©æ‚¨äº†è§£ä¸åŒæ—¥æœŸç¯„åœå…§çš„äº‹ä»¶é »ç‡è®ŠåŒ–ï¼Œé©ç”¨æ–¼ç›£æ§æˆ–è¶¨å‹¢åˆ†æã€‚

```sql
SELECT
    toStartOfDay(el.created_at) AS day,
    COUNT(el.id) AS event_count
FROM event_logs el
WHERE el.created_at >= '2025-01-01' AND el.created_at < '2025-01-31'
GROUP BY day
ORDER BY day;
```

### 4. **æ ¹æ“š Session çµ±è¨ˆæ¯å€‹ç”¨æˆ¶çš„äº‹ä»¶è§¸ç™¼æ•¸é‡**

æ­¤æŸ¥è©¢æœ‰åŠ©æ–¼åˆ†ææ¯å€‹ç”¨æˆ¶åœ¨å…¶ session ä¸­è§¸ç™¼çš„äº‹ä»¶æ•¸é‡ã€‚

```sql
SELECT
    s.user_id,
    COUNT(el.id) AS event_count
FROM event_logs el
JOIN sessions s ON el.session_id = s.id
WHERE el.created_at >= '2025-01-01' AND el.created_at < '2025-02-01'
GROUP BY s.user_id
ORDER BY event_count DESC
LIMIT 10;
```

### 5. **æŒ‰æ™‚é–“æ®µçµ±è¨ˆäº‹ä»¶æ•¸é‡å’Œå¹³å°åˆ†ä½ˆ**

æ­¤æŸ¥è©¢æä¾›æ™‚é–“æ®µå…§äº‹ä»¶çš„çµ±è¨ˆæ•¸æ“šï¼Œä¸¦é¡¯ç¤ºæ¯å€‹å¹³å°ä¸Šäº‹ä»¶çš„åˆ†ä½ˆæƒ…æ³ã€‚

```sql
SELECT
    toStartOfHour(el.created_at) AS hour,
    p.name AS platform_name,
    COUNT(el.id) AS event_count
FROM event_logs el
JOIN platforms p ON el.platform_id = p.id
WHERE el.created_at >= '2025-01-01' AND el.created_at < '2025-01-10'
GROUP BY hour, platform_name
ORDER BY hour, event_count DESC;
```

### 6. **çµ±è¨ˆæ¯å€‹æ‡‰ç”¨ç¨‹å¼çš„äº‹ä»¶ç¸½æ•¸**

é€™æœ‰åŠ©æ–¼äº†è§£æ¯å€‹æ‡‰ç”¨ç¨‹å¼çš„äº‹ä»¶æ´»å‹•æƒ…æ³ã€‚

```sql
SELECT
    a.name AS application_name,
    COUNT(el.id) AS event_count
FROM event_logs el
JOIN applications a ON el.application_id = a.id
WHERE el.created_at >= '2025-01-01' AND el.created_at < '2025-02-01'
GROUP BY application_name
ORDER BY event_count DESC
LIMIT 10;
```

### 7. **æ ¹æ“šäº‹ä»¶æ¬„ä½åˆ†æäº‹ä»¶å±¬æ€§**

å¦‚æœæ‚¨éœ€è¦æŸ¥çœ‹æŸäº›ç‰¹å®šäº‹ä»¶æ¬„ä½çš„åˆ†ä½ˆæƒ…æ³ï¼Œå¯ä»¥æ ¹æ“šäº‹ä»¶æ¬„ä½é€²è¡Œç¯©é¸å’Œçµ±è¨ˆã€‚

```sql
SELECT
    event_field.name AS field_name,
    COUNT(el.id) AS event_count
FROM event_logs el
ARRAY JOIN el.properties AS event_field
WHERE el.created_at >= '2025-01-01' AND el.created_at < '2025-02-01'
GROUP BY field_name
ORDER BY event_count DESC
LIMIT 10;
```

### 8. **è·¨å¹³å°äº‹ä»¶æ¯”è¼ƒ**

å¦‚æœæ‚¨å¸Œæœ›æ¯”è¼ƒå…©å€‹æˆ–æ›´å¤šå¹³å°ä¸Šçš„äº‹ä»¶è§¸ç™¼æ¬¡æ•¸ï¼Œå¯ä»¥ä½¿ç”¨ `JOIN` æŸ¥è©¢ä¾†å¯¦ç¾ã€‚

```sql
SELECT
    p1.name AS platform_1,
    p2.name AS platform_2,
    COUNT(el1.id) AS platform_1_event_count,
    COUNT(el2.id) AS platform_2_event_count
FROM event_logs el1
JOIN platforms p1 ON el1.platform_id = p1.id
JOIN event_logs el2 ON el1.session_id = el2.session_id
JOIN platforms p2 ON el2.platform_id = p2.id
WHERE el1.created_at >= '2025-01-01' AND el1.created_at < '2025-02-01'
AND el2.created_at >= '2025-01-01' AND el2.created_at < '2025-02-01'
GROUP BY platform_1, platform_2
ORDER BY platform_1_event_count DESC, platform_2_event_count DESC;
```

### 9. **æŒ‰ Session è¨ˆç®—æ¯å€‹ Session çš„äº‹ä»¶æ•¸é‡**

æ­¤æŸ¥è©¢å¯ä»¥å¹«åŠ©æ‚¨åˆ†ææ¯å€‹ session ä¸­çš„äº‹ä»¶è§¸ç™¼æ¬¡æ•¸ï¼Œé©åˆç”¨æ–¼åˆ†æç”¨æˆ¶è¡Œç‚ºã€‚

```sql
SELECT
    s.session_key,
    COUNT(el.id) AS event_count
FROM event_logs el
JOIN sessions s ON el.session_id = s.id
WHERE el.created_at >= '2025-01-01' AND el.created_at < '2025-02-01'
GROUP BY s.session_key
ORDER BY event_count DESC
LIMIT 10;
```

### 10. **å…¨å¹³å°äº‹ä»¶è¶¨å‹¢åœ–**

å¦‚æœéœ€è¦ç¹ªè£½å¤šå¹³å°çš„äº‹ä»¶è¶¨å‹¢ï¼Œå¯ä»¥å°‡ä¸åŒå¹³å°çš„äº‹ä»¶æ•¸é‡å°æ¯”è¦–è¦ºåŒ–ã€‚

```sql
SELECT
    toStartOfDay(el.created_at) AS day,
    p.name AS platform_name,
    COUNT(el.id) AS event_count
FROM event_logs el
JOIN platforms p ON el.platform_id = p.id
WHERE el.created_at >= '2025-01-01' AND el.created_at < '2025-01-10'
GROUP BY day, platform_name
ORDER BY day, platform_name;
```

### OLAP æŸ¥è©¢è¨­è¨ˆè¦é»ï¼š

1. **åˆç†çš„ `PARTITION BY` è¨­å®š**ï¼šç¢ºä¿å¤§æ•¸æ“šé‡çš„è¡¨æ ¼èƒ½å¤ é«˜æ•ˆåˆ†å‰²ï¼Œé€šå¸¸æŒ‰æ™‚é–“æˆ–å…¶ä»–ç¶­åº¦åˆ†å€ã€‚
2. **`JOIN` è¨­è¨ˆ**ï¼šåŸºæ–¼å¤šç¶­åº¦çš„æŸ¥è©¢éœ€æ±‚ï¼Œåˆç†è¨­è¨ˆ `JOIN` æ“ä½œï¼Œé¿å…ä¸å¿…è¦çš„è³‡æ–™æƒæã€‚
3. **ç´¢å¼•**ï¼šåˆ©ç”¨ `minmax` å’Œ `set` ç´¢å¼•ä¾†åŠ é€ŸæŸ¥è©¢ï¼Œå°¤å…¶æ˜¯æŒ‰æ™‚é–“ç¯„åœã€å¹³å°ç­‰å¸¸ç”¨ç¯©é¸æ¢ä»¶é€²è¡ŒæŸ¥è©¢æ™‚ã€‚
4. **é©ç•¶çš„æ•¸æ“šå½™ç¸½**ï¼šå°å¸¸è¦‹çš„æŸ¥è©¢é€²è¡Œèšåˆæˆ–é å…ˆè¨ˆç®—ï¼Œä»¥æ¸›å°‘æŸ¥è©¢å»¶é²ã€‚

é€™äº›æŸ¥è©¢å¯ä½œç‚ºæ‚¨é–‹å§‹é€²è¡Œ OLAP åˆ†æçš„åŸºç¤ï¼Œä¸¦å¯æ ¹æ“šéœ€æ±‚é€²ä¸€æ­¥èª¿æ•´å’Œæ“´å±•ã€‚

---

ä½ çš„ Apache NiFi Dataflow è¨­è¨ˆçœ‹èµ·ä¾†éå¸¸å®Œæ•´ï¼Œä½†æˆ‘æœƒåšä¸€äº›ç´°å¾®èª¿æ•´å’Œä¿®æ­£ï¼Œä»¥ç¢ºä¿æµç¨‹é †åˆ©é‹è¡Œï¼Œä¸¦åœ¨å¿…è¦æ™‚æ¾„æ¸…ä¸€äº›ç´°ç¯€ã€‚é€™æ˜¯èª¿æ•´å¾Œçš„ç‰ˆæœ¬ï¼š

---

## ğŸ”„ **Apache NiFi Dataflow è¨­è¨ˆ**

### ğŸ§© **å…ƒä»¶æµç¨‹**

```
ConsumeKafka â†’ ReplaceText â†’ ConvertRecord â†’ PutClickHouseRecord
```

### **è©³ç´°æ­¥é©Ÿèªªæ˜ï¼š**

#### 1. `ConsumeKafka_2_0`

- **Topic Name**ï¼š`event_logs.*.*` (è¨‚é–±å¤šå€‹å¹³å°çš„äº‹ä»¶è³‡æ–™)
- **Record Reader**ï¼š`JsonTreeReader`ï¼ˆè§£æ JSON è³‡æ–™ï¼‰
- **Record Writer**ï¼š`JsonRecordSetWriter`ï¼ˆå¯«å…¥ JSON æ ¼å¼ï¼‰
- è‡ªå‹•è¨‚é–±æ‰€æœ‰å¹³å°çš„äº‹ä»¶è³‡æ–™

#### 2. `ReplaceText`

- å¯åŠ ä¸Šé‚è¼¯è½‰æ› `created_at` æ ¼å¼æˆ–è£œä¸Šç¼ºå¤±æ¬„ä½ï¼ˆå¦‚ `tenant_id` ç­‰ï¼‰
- ç”¨ä½œè‡¨æ™‚è™•ç†é»ï¼Œä¾‹å¦‚è£œå……ç¼ºå¤±çš„æ¬„ä½æˆ–ä¿®æ­£æ ¼å¼

#### 3. `ConvertRecord`

- **Record Reader**ï¼š`JsonTreeReader`
- **Record Writer**ï¼š`ClickHouseRecordSetWriter`
- å®šç¾© ClickHouse è¡¨çµæ§‹å°æ‡‰çš„ schemaï¼Œä¸¦è½‰æ›è³‡æ–™æ ¼å¼ç‚º ClickHouse å…¼å®¹çš„æ ¼å¼

#### 4. `PutClickHouseRecord`

- **Database Connection Pooling Service**ï¼šè¨­å®š ClickHouse JDBC é€£ç·šæ± 
- **Table Name**ï¼š`event_logs`
- **Batch Size**ï¼š500\~1000ï¼ˆæ ¹æ“šæµé‡èª¿æ•´ï¼‰
- å¯é€²ä¸€æ­¥èª¿æ•´å¯«å…¥è³‡æ–™é‡ä»¥é©æ‡‰å¯¦éš›éœ€æ±‚

---

## ğŸ” **å®‰å…¨èˆ‡é«˜å¯ç”¨å»ºè­°**

- **Kafka é…ç½®**ï¼š

  - è¨­å®š `message.max.bytes` ä»¥æ”¯æ´è¼ƒå¤§çš„äº‹ä»¶è³‡æ–™
  - é–‹å•Ÿ Kafka çš„è³‡æ–™å£“ç¸®åŠŸèƒ½ï¼šæ¨è–¦ä½¿ç”¨ `lz4` æˆ– `snappy`

- **NiFi é…ç½®**ï¼š

  - NiFi é€²è¡Œæ‰¹æ¬¡è™•ç†ï¼ˆä¸é€ç­†å¯«å…¥ï¼‰ï¼Œä»¥æé«˜æ•ˆç‡ä¸¦æ¸›å°‘ ClickHouse è³‡æ–™åº«çš„è² æ“”

- **ClickHouse é«˜å¯ç”¨è¨­ç½®**ï¼š

  - å•Ÿç”¨ Zookeeper èˆ‡ `ReplicatedMergeTree` å¼•æ“ä¾†æ”¯æ´ ClickHouse çš„é«˜å¯ç”¨èˆ‡å®¹éŒ¯èƒ½åŠ›

---

## ğŸ“Š **Grafana æ•´åˆ ClickHouse**

1. å®‰è£ [ClickHouse Grafana æ’ä»¶](https://grafana.com/grafana/plugins/vertamedia-clickhouse-datasource/)
2. é…ç½® ClickHouse Data Source
3. ç¯„ä¾‹æŸ¥è©¢ï¼š

```sql
SELECT
  toStartOfHour(created_at) AS hour,
  count() AS total_events
FROM event_logs
WHERE event_name = 'page_view'
  AND event_date >= today() - 1
GROUP BY hour
ORDER BY hour
```

é€™å€‹æŸ¥è©¢å¯ä»¥å¹«åŠ©ä½ æŸ¥çœ‹æœ€è¿‘ä¸€å¤©å…§æ¯å°æ™‚çš„äº‹ä»¶æ•¸é‡ã€‚

---

## ğŸ“ **NiFi Flow Template XML ç¯„æœ¬**

ä»¥ä¸‹æ˜¯ NiFi Flow Template çš„ç¯„æœ¬ï¼Œå°‡æœƒè‡ªå‹•åŒ– Kafka æ¶ˆè²»ã€è³‡æ–™è½‰æ›åŠå¯«å…¥ ClickHouse çš„éç¨‹ï¼š

```xml
<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<template>
  <name>Multi-Tenant Event Tracking Flow</name>
  <description>Consume Kafka â†’ ConvertRecord â†’ PutClickHouseRecord (with multi-tenant support)</description>
  <snippet>
    <connections/>
    <processors>
      <!-- Kafka Consumer -->
      <processor>
        <name>ConsumeKafka_2_0</name>
        <class>org.apache.nifi.kafka.pubsub.ConsumeKafka_2_0</class>
        <config>
          <properties>
            <property>
              <name>Kafka Topic Name</name>
              <value>event_logs.*.*</value>
            </property>
            <property>
              <name>Record Reader</name>
              <value>JsonTreeReader</value>
            </property>
            <property>
              <name>Record Writer</name>
              <value>JsonRecordSetWriter</value>
            </property>
            <property>
              <name>Group ID</name>
              <value>event-tracker-group</value>
            </property>
            <property>
              <name>Offset Reset</name>
              <value>earliest</value>
            </property>
          </properties>
        </config>
      </processor>

      <!-- Record Transformation (Convert to multi-tenant structure) -->
      <processor>
        <name>ConvertRecord</name>
        <class>org.apache.nifi.processors.standard.ConvertRecord</class>
        <config>
          <properties>
            <property>
              <name>Record Reader</name>
              <value>JsonTreeReader</value>
            </property>
            <property>
              <name>Record Writer</name>
              <value>ClickHouseRecordSetWriter</value>
            </property>
            <property>
              <name>Additional Field Mapping</name>
              <value>tenant_id = ${tenant_id}</value> <!-- Mapping tenant_id -->
            </property>
          </properties>
        </config>
      </processor>

      <!-- ClickHouse Sink -->
      <processor>
        <name>PutClickHouseRecord</name>
        <class>org.apache.nifi.clickhouse.PutClickHouseRecord</class>
        <config>
          <properties>
            <property>
              <name>Database Connection Pooling Service</name>
              <value>ClickHouseConnectionPool</value>
            </property>
            <property>
              <name>Table Name</name>
              <value>event_logs</value>
            </property>
            <property>
              <name>Batch Size</name>
              <value>500</value>
            </property>
            <property>
              <name>Additional Fields</name>
              <value>tenant_id, application_id, session_id, event_id, platform_id, created_at, properties</value> <!-- Ensure multi-tenant fields are inserted -->
            </property>
          </properties>
        </config>
      </processor>
    </processors>
  </snippet>
</template>
```

---

### **JSON Schemaï¼ˆä¾› JsonTreeReader ä½¿ç”¨ï¼‰**

```json
{
  "type": "record",
  "name": "EventLog",
  "fields": [
    { "name": "tenant_id", "type": "string" },
    { "name": "platform", "type": "string" },
    { "name": "session_id", "type": "string" },
    { "name": "event_key", "type": "string" },
    { "name": "event_version", "type": "string" },
    { "name": "event_time", "type": "string" },
    { "name": "attributes", "type": { "type": "map", "values": "string" } },
    { "name": "created_at", "type": "string" }
  ]
}
```

é€™ä»½ JSON Schema ç”¨ä¾†è¨­ç½® `JsonTreeReader`ï¼Œç¢ºä¿ NiFi æ­£ç¢ºè§£æäº‹ä»¶è³‡æ–™çš„å„å€‹æ¬„ä½ï¼Œä¸¦æ ¹æ“šéœ€è¦é€²è¡Œè™•ç†ã€‚
